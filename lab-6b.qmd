---
title: "Lab 6: Machine Learning in Hydrology â€“ ESS 330"
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
project:
  type: website
  output-dir: docs
---

```{r setup, include=FALSE}
library(tidyverse)
library(readr)      
library(tidymodels)
library(baguette)
library(glue)
library(powerjoin)
library(ggthemes)
library(patchwork)
library(scales)
library(purrr)

```

```{r}
## ðŸ”¹ Q1: Download Data (10 pts)
# Create data folder
if (!dir.exists("data")) dir.create("data")

# Download the PDF documentation
pdf_url <- "https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf"
download.file(pdf_url, destfile = "data/camels_attributes_v2.0.pdf")

# Download all data types
root <- 'https://gdex.ucar.edu/dataset/camels/file'
types <- c("clim", "geol", "soil", "topo", "vege", "hydro")
remote_files <- glue('{root}/camels_{types}.txt')
local_files  <- glue('data/camels_{types}.txt')
walk2(remote_files, local_files, download.file, quiet = TRUE)

# Read and merge the data
camels <- map(local_files, read_delim, show_col_types = FALSE)
camels <- power_full_join(camels, by = 'gauge_id')

# Add log of q_mean
camels <- camels |> mutate(logQmean = log(q_mean))
```

```{r}
## ðŸ”¹ Q2: Make 2 Maps (10 pts)
p1 <- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = aridity)) +
  scale_color_viridis_c() +
  ggtitle("Aridity across CAMELS sites") +
  theme_map()

p2 <- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = p_mean)) +
  scale_color_viridis_c() +
  ggtitle("Mean Precipitation (p_mean)") +
  theme_map()

p1 + p2
```

```{r}
## ðŸ”¹ Q3: Build xgboost and neural net models (20 pts)
# Split data for modeling
set.seed(42)
split <- initial_split(camels, prop = 0.75)
camels_train <- training(split)
camels_test <- testing(split)
camels_cv <- vfold_cv(camels_train, v = 10)

# Define recipe
rec <- recipe(logQmean ~ aridity + p_mean, data = camels_train) |> 
  step_log(all_predictors()) |> 
  step_naomit(all_predictors(), all_outcomes())

# Define models
rf_model <- rand_forest(trees = 500) |> set_engine("ranger", importance = "impurity") |> set_mode("regression")
xgb_model <- boost_tree(trees = 1000, learn_rate = 0.05) |> set_engine("xgboost") |> set_mode("regression")
nnet_model <- bag_mlp() |> set_engine("nnet") |> set_mode("regression")

# Build workflow set
wf_set <- workflow_set(
  preproc = list(rec),
  models = list(rf_model, xgb_model, nnet_model)
) |> 
  workflow_map("fit_resamples", resamples = camels_cv)

# Visualize results
autoplot(wf_set)
rank_results(wf_set, rank_metric = "rsq", select_best = TRUE)

```
