[
  {
    "objectID": "lab-6b.html",
    "href": "lab-6b.html",
    "title": "Lab 6: Machine Learning â€“ ESS 330",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.4     âœ” readr     2.1.5\nâœ” forcats   1.0.0     âœ” stringr   1.5.1\nâœ” ggplot2   3.5.1     âœ” tibble    3.2.1\nâœ” lubridate 1.9.4     âœ” tidyr     1.3.1\nâœ” purrr     1.0.4     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(readr)\nlibrary(tidymodels)\n\n\nWarning: package 'tidymodels' was built under R version 4.4.3\n\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.3.0 â”€â”€\nâœ” broom        1.0.7     âœ” rsample      1.2.1\nâœ” dials        1.4.0     âœ” tune         1.3.0\nâœ” infer        1.0.7     âœ” workflows    1.2.0\nâœ” modeldata    1.4.0     âœ” workflowsets 1.1.0\nâœ” parsnip      1.3.1     âœ” yardstick    1.3.2\nâœ” recipes      1.2.1     \n\n\nWarning: package 'broom' was built under R version 4.4.3\n\n\nWarning: package 'dials' was built under R version 4.4.3\n\n\nWarning: package 'parsnip' was built under R version 4.4.3\n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\nWarning: package 'tune' was built under R version 4.4.3\n\n\nWarning: package 'workflows' was built under R version 4.4.3\n\n\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\nâœ– scales::discard() masks purrr::discard()\nâœ– dplyr::filter()   masks stats::filter()\nâœ– recipes::fixed()  masks stringr::fixed()\nâœ– dplyr::lag()      masks stats::lag()\nâœ– yardstick::spec() masks readr::spec()\nâœ– recipes::step()   masks stats::step()\n\n\nCode\nlibrary(baguette)\n\n\nWarning: package 'baguette' was built under R version 4.4.3\n\n\nCode\nlibrary(glue)\n\n\nWarning: package 'glue' was built under R version 4.4.3\n\n\nCode\nlibrary(powerjoin)\n\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\n\nCode\nlibrary(ggthemes)\n\n\nWarning: package 'ggthemes' was built under R version 4.4.3\n\n\nCode\nlibrary(patchwork)\n\n\nWarning: package 'patchwork' was built under R version 4.4.3\n\n\nCode\nlibrary(scales)"
  },
  {
    "objectID": "lab-6b.html#q1-download-data",
    "href": "lab-6b.html#q1-download-data",
    "title": "Lab 6: Machine Learning â€“ ESS 330",
    "section": "ðŸ”¹ Q1: Download Data",
    "text": "ðŸ”¹ Q1: Download Data\n\n\nCode\n# Create data folder\nif (!dir.exists(\"data\")) dir.create(\"data\")\n\n# Download the PDF documentation\npdf_url &lt;- \"https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf\"\ndownload.file(pdf_url, destfile = \"data/camels_attributes_v2.0.pdf\")\n\n# Download all data types\nroot &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\nremote_files &lt;- paste0(root, \"/camels_\", types, \".txt\")\nlocal_files  &lt;- paste0(\"data/camels_\", types, \".txt\")\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\n# Read and merge the data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE)\ncamels &lt;- power_full_join(camels, by = 'gauge_id')\n\n# Add log of q_mean\ncamels &lt;- camels |&gt; mutate(logQmean = log(q_mean))"
  },
  {
    "objectID": "lab-6b.html#q2-make-2-maps",
    "href": "lab-6b.html#q2-make-2-maps",
    "title": "Lab 6: Machine Learning â€“ ESS 330",
    "section": "ðŸ”¹ Q2: Make 2 Maps",
    "text": "ðŸ”¹ Q2: Make 2 Maps\n\n\nCode\np1 &lt;- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = aridity)) +\n  scale_color_viridis_c() +\n  ggtitle(\"Aridity across CAMELS sites\") +\n  theme_map()\n\np2 &lt;- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = p_mean)) +\n  scale_color_viridis_c() +\n  ggtitle(\"Mean Precipitation (p_mean)\") +\n  theme_map()\n\np1 + p2\n\n\n\n\n\n\n\n\n\nExplanation: These maps help us understand geographic patterns in aridity and precipitation, which are key predictors of streamflow."
  },
  {
    "objectID": "lab-6b.html#q3-build-xgboost-and-neural-net-models",
    "href": "lab-6b.html#q3-build-xgboost-and-neural-net-models",
    "title": "Lab 6: Machine Learning â€“ ESS 330",
    "section": "ðŸ”¹ Q3: Build xgboost and neural net models",
    "text": "ðŸ”¹ Q3: Build xgboost and neural net models\n\n\nCode\n# Split data for modeling\nset.seed(42)\nsplit &lt;- initial_split(camels, prop = 0.75)\ncamels_train &lt;- training(split)\ncamels_test &lt;- testing(split)\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n# Define recipe\nrec &lt;- recipe(logQmean ~ aridity + p_mean, data = camels_train) |&gt; \n  step_log(all_predictors()) |&gt; \n  step_naomit(all_predictors(), all_outcomes())\n\n# Define models\nrf_model &lt;- rand_forest(trees = 500) |&gt; set_engine(\"ranger\", importance = \"impurity\") |&gt; set_mode(\"regression\")\nxgb_model &lt;- boost_tree(trees = 1000, learn_rate = 0.05) |&gt; set_engine(\"xgboost\") |&gt; set_mode(\"regression\")\nnnet_model &lt;- bag_mlp() |&gt; set_engine(\"nnet\") |&gt; set_mode(\"regression\")\n\n# Build workflow set\nwf_set &lt;- workflow_set(\n  preproc = list(rec),\n  models = list(rf_model, xgb_model, nnet_model)\n) |&gt; \n  workflow_map(\"fit_resamples\", resamples = camels_cv)\n\n\nWarning: package 'ranger' was built under R version 4.4.3\n\n\nWarning: package 'xgboost' was built under R version 4.4.3\n\n\nWarning: package 'nnet' was built under R version 4.4.3\n\n\nCode\n# Visualize results\nautoplot(wf_set)\n\n\n\n\n\n\n\n\n\nCode\nrank_results(wf_set, rank_metric = \"rsq\", select_best = TRUE)\n\n\n# A tibble: 6 Ã— 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_bag_mlp    Preproâ€¦ rmse    0.511  0.0327    10 recipe       bag_â€¦     1\n2 recipe_bag_mlp    Preproâ€¦ rsq     0.783  0.0360    10 recipe       bag_â€¦     1\n3 recipe_rand_foreâ€¦ Preproâ€¦ rmse    0.541  0.0342    10 recipe       randâ€¦     2\n4 recipe_rand_foreâ€¦ Preproâ€¦ rsq     0.767  0.0387    10 recipe       randâ€¦     2\n5 recipe_boost_tree Preproâ€¦ rmse    0.622  0.0370    10 recipe       boosâ€¦     3\n6 recipe_boost_tree Preproâ€¦ rsq     0.711  0.0430    10 recipe       boosâ€¦     3\n\n\nExplanation: The autoplot shows cross-validated RMSE and RÂ² for each model. I select the best model based on RÂ²."
  },
  {
    "objectID": "lab-6b.html#q4-build-your-own",
    "href": "lab-6b.html#q4-build-your-own",
    "title": "Lab 6: Machine Learning â€“ ESS 330",
    "section": "ðŸ”¹ Q4: Build your own",
    "text": "ðŸ”¹ Q4: Build your own\n\nQ4a: Data Splitting\n\n\nCode\nset.seed(101)\nsplit &lt;- initial_split(camels, prop = 0.75)\ntrain &lt;- training(split)\ntest &lt;- testing(split)\ncv &lt;- vfold_cv(train, v = 10)\n\n\n\n\nQ4b: Recipe\n\n\nCode\n# Ensure 'train' is already defined before this step\nmy_recipe &lt;- recipe(logQmean ~ aridity + p_mean + elev_mean + slope_mean, data = train) |&gt; \n  step_log(all_predictors()) |&gt; \n  step_normalize(all_predictors()) |&gt; \n  step_naomit(all_predictors(), all_outcomes())\n\n\n\n\nQ4c: Define 3 Models\n\n\nCode\nmodel_rf &lt;- rand_forest(trees = 500) |&gt; set_engine(\"ranger\") |&gt; set_mode(\"regression\")\nmodel_xgb &lt;- boost_tree(trees = 1000, learn_rate = 0.05) |&gt; set_engine(\"xgboost\") |&gt; set_mode(\"regression\")\nmodel_nn &lt;- bag_mlp() |&gt; set_engine(\"nnet\") |&gt; set_mode(\"regression\")\n\n\n\n\nQ4d: Workflow Set\n\n\nCode\nmy_wf_set &lt;- workflow_set(\n  preproc = list(my_recipe),\n  models = list(model_rf, model_xgb, model_nn)\n) |&gt; \n  workflow_map(\"fit_resamples\", resamples = cv)\n\n\n\n\nQ4e: Evaluation\n\n\nCode\nautoplot(my_wf_set)\n\n\n\n\n\n\n\n\n\nCode\nrank_results(my_wf_set, rank_metric = \"rsq\", select_best = TRUE)\n\n\n# A tibble: 6 Ã— 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_bag_mlp    Preproâ€¦ rmse    0.330  0.0247    10 recipe       bag_â€¦     1\n2 recipe_bag_mlp    Preproâ€¦ rsq     0.923  0.0109    10 recipe       bag_â€¦     1\n3 recipe_rand_foreâ€¦ Preproâ€¦ rmse    0.349  0.0307    10 recipe       randâ€¦     2\n4 recipe_rand_foreâ€¦ Preproâ€¦ rsq     0.910  0.0135    10 recipe       randâ€¦     2\n5 recipe_boost_tree Preproâ€¦ rmse    0.387  0.0278    10 recipe       boosâ€¦     3\n6 recipe_boost_tree Preproâ€¦ rsq     0.895  0.0127    10 recipe       boosâ€¦     3\n\n\nExplanation: This step shows model performance across resamples. I choose the model with the highest RÂ².\n\n\nQ4f: Extract and Evaluate Best Model on Test Set\n\n\nCode\nbest_model_id &lt;- pull(rank_results(my_wf_set, rank_metric = \"rsq\", select_best = TRUE), wflow_id)[1]\nfinal_wf &lt;- extract_workflow(my_wf_set, id = best_model_id)\nfinal_fit &lt;- final_wf |&gt; fit(data = train)\nfinal_data &lt;- augment(final_fit, new_data = test)\n\n# Evaluate\nmetrics(final_data, truth = logQmean, estimate = .pred)\n\n\n# A tibble: 3 Ã— 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.336\n2 rsq     standard       0.920\n3 mae     standard       0.214\n\n\nCode\n# Plot\nggplot(final_data, aes(x = logQmean, y = .pred, color = aridity)) +\n  geom_point() +\n  geom_abline(linetype = 2, color = \"red\") +\n  theme_linedraw() +\n  labs(title = \"Observed vs Predicted Log Mean Flow\",\n       x = \"Observed\",\n       y = \"Predicted\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n\n\nExplanation: This final step shows how well the best model generalizes to unseen data. A tight cluster along the 1:1 line indicates strong predictive performance."
  },
  {
    "objectID": "hyperparameter-tuning.html",
    "href": "hyperparameter-tuning.html",
    "title": "Hyperparameter Tuning",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(skimr)\nlibrary(visdat)\nlibrary(ggpubr)\nlibrary(powerjoin)\nlibrary(patchwork)\nlibrary(ggthemes)\n\n\n# Download the PDF documentation\npdf_url &lt;- \"https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf\"\ndownload.file(pdf_url, destfile = \"data/camels_attributes_v2.0.pdf\")\n\n# Download all data types\nroot &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\nremote_files &lt;- paste0(root, \"/camels_\", types, \".txt\")\nlocal_files  &lt;- paste0(\"data/camels_\", types, \".txt\")\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\n# Read and merge the data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE)\ncamels &lt;- power_full_join(camels, by = 'gauge_id')\n\n# Add log of q_mean\ncamels &lt;- camels |&gt; mutate(logQmean = log(q_mean))\n\n\nset.seed(101)\nsplit &lt;- initial_split(camels, prop = 0.75)\ntrain &lt;- training(split)\ntest &lt;- testing(split)\ncv &lt;- vfold_cv(train, v = 10)\n\n\nmy_recipe &lt;- recipe(logQmean ~ aridity + p_mean + elev_mean + slope_mean, data = train) |&gt; \n  step_log(all_predictors()) |&gt; \n  step_normalize(all_predictors()) |&gt; \n  step_naomit(all_predictors(), all_outcomes())\n\n\nDefining a tunable model\n\n# Defining a tunable XGBoost model\nxgb_tune &lt;- boost_tree(\n  trees = tune(),\n  learn_rate = tune(),\n  tree_depth = tune()\n) |&gt; \n  set_engine(\"xgboost\") |&gt; \n  set_mode(\"regression\")\n\n\n\nCreating a workflow for tuning\n\n# Using the same recipe from Lab 6\nwf_tune &lt;- workflow() |&gt; \n  add_model(xgb_tune) |&gt; \n  add_recipe(my_recipe)\n\n\n\nExploring tunable hyperparameter ranges\n\ndials &lt;- extract_parameter_set_dials(wf_tune)\ndials\n\nCollection of 3 parameters for tuning\n\n\n\n\n\n identifier       type    object\n      trees      trees nparam[+]\n tree_depth tree_depth nparam[+]\n learn_rate learn_rate nparam[+]\n\n\n\n\n\n\n\nCreating the search grid\n\n# Create a Latin Hypercube grid\nset.seed(123)\nmy.grid &lt;- grid_latin_hypercube(dials, size = 25)\n\nWarning: `grid_latin_hypercube()` was deprecated in dials 1.3.0.\nâ„¹ Please use `grid_space_filling()` instead.\n\n\n\n\nTuning the model using the grid\n\n# Tune over the resamples\nmodel_params &lt;- tune_grid(\n  wf_tune,\n  resamples = cv,  # from Lab 6\n  grid = my.grid,\n  metrics = metric_set(rmse, rsq, mae),\n  control = control_grid(save_pred = TRUE)\n)\n\nWarning: package 'xgboost' was built under R version 4.4.3\n\n\n\n\nVisualize tuning results\n\nautoplot(model_params)\n\n\n\n\n\n\n\n\n\ncollect_metrics(model_params) |&gt; \n  arrange(mean)\n\n# A tibble: 75 Ã— 9\n   trees tree_depth learn_rate .metric .estimator  mean     n std_err .config   \n   &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1   306         10    0.0149  mae     standard   0.235    10  0.0155 Preprocesâ€¦\n 2  1415          8    0.00317 mae     standard   0.236    10  0.0150 Preprocesâ€¦\n 3  1589         12    0.00993 mae     standard   0.237    10  0.0169 Preprocesâ€¦\n 4   842         12    0.0171  mae     standard   0.237    10  0.0173 Preprocesâ€¦\n 5  1090          6    0.0101  mae     standard   0.238    10  0.0146 Preprocesâ€¦\n 6   621          5    0.0371  mae     standard   0.238    10  0.0146 Preprocesâ€¦\n 7   977         11    0.0649  mae     standard   0.238    10  0.0173 Preprocesâ€¦\n 8  1483         15    0.00787 mae     standard   0.239    10  0.0174 Preprocesâ€¦\n 9   109          7    0.117   mae     standard   0.239    10  0.0165 Preprocesâ€¦\n10  1786         13    0.00562 mae     standard   0.240    10  0.0164 Preprocesâ€¦\n# â„¹ 65 more rows\n\n\n\nshow_best(model_params, metric = \"mae\")\n\n# A tibble: 5 Ã— 9\n  trees tree_depth learn_rate .metric .estimator  mean     n std_err .config    \n  &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      \n1   306         10    0.0149  mae     standard   0.235    10  0.0155 Preprocessâ€¦\n2  1415          8    0.00317 mae     standard   0.236    10  0.0150 Preprocessâ€¦\n3  1589         12    0.00993 mae     standard   0.237    10  0.0169 Preprocessâ€¦\n4   842         12    0.0171  mae     standard   0.237    10  0.0173 Preprocessâ€¦\n5  1090          6    0.0101  mae     standard   0.238    10  0.0146 Preprocessâ€¦\n\nhp_best &lt;- select_best(model_params, metric = \"mae\")\n\nAfter tuning the XGBoost model, the best combination of hyperparameters included 306 trees, a tree depth of 10, and a learning rate around 0.015. This setup gave the lowest mean absolute error (MAE) of about 0.235 during cross-validation. What stood out to me is that the top few combinations all performed pretty similarly, which makes me feel more confident that the model is stable and not just getting lucky with one specific set of values.\n\n\nFinalizing the workflow\n\nfinal_wf &lt;- finalize_workflow(wf_tune, hp_best)\n\n\n\nFitting and evaluate on the test set\n\nfinal_fit &lt;- last_fit(final_wf, split)\n\n# Metrics\ncollect_metrics(final_fit)\n\n# A tibble: 2 Ã— 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.354 Preprocessor1_Model1\n2 rsq     standard       0.912 Preprocessor1_Model1\n\n# Predictions\npreds &lt;- collect_predictions(final_fit)\n\n# Plot predicted vs actual\nggplot(preds, aes(x = .pred, y = logQmean)) +\n  geom_point() +\n  geom_abline(linetype = \"dashed\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(title = \"Final Model: Predicted vs Observed\", x = \"Predicted\", y = \"Observed\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWhen I tested the final model on the test dataset, it had an RMSE of about 0.354 and an RÂ² of 0.912. That means it explained more than 91% of the variation in logQmean, which I think is a strong result for this kind of regression problem. The low RMSE also tells me the modelâ€™s predictions are pretty close to the actual values. So overall, Iâ€™d say it generalizes well and didnâ€™t just perform well during training.\nThe scatter plot of predicted vs actual logQmean shows a really tight alignment along the 1:1 line. That tells me the model is doing a solid job â€” itâ€™s not systematically overpredicting or underpredicting. I also added a smoothed line with geom_smooth(), and it basically follows the diagonal, which is a good sign that the model is learning the overall pattern accurately.\n\n\nMapping predictions and residuals\n\n# Fit to full dataset\nfit_final &lt;- fit(final_wf, data = camels)\n\n# Augment with predictions\ncamels_aug &lt;- augment(fit_final, new_data = camels) |&gt; \n  mutate(residual = (logQmean - .pred)^2)\n\n# Plot predictions map\np_pred &lt;- ggplot(camels_aug, aes(x = gauge_lon, y = gauge_lat, color = .pred)) +\n  borders(\"state\") +\n  geom_point() +\n  scale_color_viridis_c() +\n  labs(title = \"Predicted logQmean\") +\n  theme_map()\n\n# Plot residuals map\np_resid &lt;- ggplot(camels_aug, aes(x = gauge_lon, y = gauge_lat, color = residual)) +\n  borders(\"state\") +\n  geom_point() +\n  scale_color_viridis_c() +\n  labs(title = \"Squared Residuals\") +\n  theme_map()\n\n# Combine maps\np_pred + p_resid\n\n\n\n\n\n\n\n\nThe map of predicted logQmean looks smooth and seems to reflect regional differences in climate or terrain across the U.S. I think this means the model picked up on some real geographic trends in streamflow. The residual map mostly shows small errors, though a few spots have higher values. Those might be sites where streamflow is influenced by something the model didnâ€™t capture â€” like human intervention or more localized features. But overall, the model seems to do well across most areas."
  }
]