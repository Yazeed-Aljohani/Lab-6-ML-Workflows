[
  {
    "objectID": "lab-6b.html",
    "href": "lab-6b.html",
    "title": "Lab 6: Machine Learning in Hydrology â€“ ESS 330",
    "section": "",
    "text": "Code\n## ðŸ”¹ Q1: Download Data (10 pts)\n# Create data folder\nif (!dir.exists(\"data\")) dir.create(\"data\")\n\n# Download the PDF documentation\npdf_url &lt;- \"https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf\"\ndownload.file(pdf_url, destfile = \"data/camels_attributes_v2.0.pdf\")\n\n# Download all data types\nroot &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\nremote_files &lt;- glue('{root}/camels_{types}.txt')\nlocal_files  &lt;- glue('data/camels_{types}.txt')\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\n# Read and merge the data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE)\ncamels &lt;- power_full_join(camels, by = 'gauge_id')\n\n# Add log of q_mean\ncamels &lt;- camels |&gt; mutate(logQmean = log(q_mean))\n\n\n\n\nCode\n## ðŸ”¹ Q2: Make 2 Maps (10 pts)\np1 &lt;- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = aridity)) +\n  scale_color_viridis_c() +\n  ggtitle(\"Aridity across CAMELS sites\") +\n  theme_map()\n\np2 &lt;- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = p_mean)) +\n  scale_color_viridis_c() +\n  ggtitle(\"Mean Precipitation (p_mean)\") +\n  theme_map()\n\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\nCode\n## ðŸ”¹ Q3: Build xgboost and neural net models (20 pts)\n# Split data for modeling\nset.seed(42)\nsplit &lt;- initial_split(camels, prop = 0.75)\ncamels_train &lt;- training(split)\ncamels_test &lt;- testing(split)\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n# Define recipe\nrec &lt;- recipe(logQmean ~ aridity + p_mean, data = camels_train) |&gt; \n  step_log(all_predictors()) |&gt; \n  step_naomit(all_predictors(), all_outcomes())\n\n# Define models\nrf_model &lt;- rand_forest(trees = 500) |&gt; set_engine(\"ranger\", importance = \"impurity\") |&gt; set_mode(\"regression\")\nxgb_model &lt;- boost_tree(trees = 1000, learn_rate = 0.05) |&gt; set_engine(\"xgboost\") |&gt; set_mode(\"regression\")\nnnet_model &lt;- bag_mlp() |&gt; set_engine(\"nnet\") |&gt; set_mode(\"regression\")\n\n# Build workflow set\nwf_set &lt;- workflow_set(\n  preproc = list(rec),\n  models = list(rf_model, xgb_model, nnet_model)\n) |&gt; \n  workflow_map(\"fit_resamples\", resamples = camels_cv)\n\n\nWarning: package 'ranger' was built under R version 4.4.3\n\n\nWarning: package 'xgboost' was built under R version 4.4.3\n\n\nWarning: package 'nnet' was built under R version 4.4.3\n\n\nCode\n# Visualize results\nautoplot(wf_set)\n\n\n\n\n\n\n\n\n\nCode\nrank_results(wf_set, rank_metric = \"rsq\", select_best = TRUE)\n\n\n# A tibble: 6 Ã— 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_bag_mlp    Preproâ€¦ rmse    0.511  0.0327    10 recipe       bag_â€¦     1\n2 recipe_bag_mlp    Preproâ€¦ rsq     0.783  0.0360    10 recipe       bag_â€¦     1\n3 recipe_rand_foreâ€¦ Preproâ€¦ rmse    0.541  0.0342    10 recipe       randâ€¦     2\n4 recipe_rand_foreâ€¦ Preproâ€¦ rsq     0.767  0.0387    10 recipe       randâ€¦     2\n5 recipe_boost_tree Preproâ€¦ rmse    0.622  0.0370    10 recipe       boosâ€¦     3\n6 recipe_boost_tree Preproâ€¦ rsq     0.711  0.0430    10 recipe       boosâ€¦     3"
  }
]